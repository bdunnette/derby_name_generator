{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "derby_names.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bdunnette/derby_name_generator/blob/master/derby_names.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fMO1Y1Qj5LWt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Based on Max Woolf's notebook: https://drive.google.com/file/d/1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK/view?usp=sharing\n",
        "\n",
        "Inspired by Janelle Shane's blog post: http://aiweirdness.com/post/174466734677/neural-network-generated-roller-derby-names"
      ]
    },
    {
      "metadata": {
        "id": "j5sZ7k49z9FR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q textgenrnn tensorflowjs\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "training_file = \"derby_names.txt\"\n",
        "model_name = 'derbynames' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hivPLDl5C3zs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_cfg = {\n",
        "    'word_level': False,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 3,   # number of LSTM layers (>=2 recommended)\n",
        "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 20,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 20,   # set higher to train the model for longer\n",
        "    'gen_epochs': 5,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0.2,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v0o8T_WdCy7X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "name_set = set()\n",
        "session = requests.Session()\n",
        "\n",
        "r1 = session.get(\"https://www.twoevils.org/rollergirls/\")\n",
        "d1 = r1.text\n",
        "soup1 = BeautifulSoup(d1, \"lxml\")\n",
        "rows1 = soup1.find_all('tr', {'class':['trc1', 'trc2']})\n",
        "\n",
        "for idx, row in enumerate(rows1):\n",
        "    td = row.find('td')\n",
        "    name_set.add(td.get_text())\n",
        "\n",
        "r2 = session.get(\"http://www.derbyrollcall.com/everyone\")\n",
        "d2 = r2.text\n",
        "soup2 = BeautifulSoup(d2, \"lxml\")\n",
        "rows2 = soup2.find_all('td', {'class':'name'})\n",
        "\n",
        "for idx, td in enumerate(rows2):\n",
        "    name_set.add(td.get_text())\n",
        "    \n",
        "with open(training_file,\"w\") as names_file:\n",
        "    name_list = list(name_set)\n",
        "    names_file.writelines(\"%s\\n\" % n for n in name_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wfg9-JRr09Z9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=training_file,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=1024,\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=100,\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AY-pMFlw4sYL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this temperature schedule cycles between 1 very unexpected token, 1 unexpected token, 2 expected tokens, repeat.\n",
        "# changing the temperature schedule can result in wildly different output!\n",
        "from datetime import datetime\n",
        "temperature = [1.0, 0.5, 0.5, 0.2]   \n",
        "prefix = None   # if you want each generated text to start with a given seed text\n",
        "\n",
        "if train_cfg['line_delimited']:\n",
        "  n = 1000\n",
        "  max_gen_length = 60 if model_cfg['word_level'] else 300\n",
        "else:\n",
        "  n = 10\n",
        "  max_gen_length = 2000 if model_cfg['word_level'] else 10000\n",
        "  \n",
        "generated_names = textgen.generate(n=n, temperature=temperature, return_as_list=True)[0].split('\\n')\n",
        "\n",
        "new_names = [n for n in generated_names if n not in name_list]\n",
        "print(new_names)\n",
        "\n",
        "timestring = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "gen_file = '{}_gentext_{}.txt'.format(model_name, timestring)\n",
        "\n",
        "with open(gen_file, 'w') as f:\n",
        "  f.writelines(\"%s\\n\" % n for n in new_names)\n",
        "\n",
        "\n",
        "# textgen.generate_to_file(gen_file,\n",
        "#                          temperature=temperature,\n",
        "#                          prefix=prefix,\n",
        "#                          n=n,\n",
        "#                          max_gen_length=max_gen_length)\n",
        "\n",
        "files.download(gen_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cydo9Gro4zcz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflowjs as tfjs\n",
        "model_export_dir = \"{}_tfjs\".format(model_name)\n",
        "tfjs.converters.save_keras_model(textgen.model, model_export_dir)\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))\n",
        "files.download('{}_weights.hdf5'.format(model_name))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}